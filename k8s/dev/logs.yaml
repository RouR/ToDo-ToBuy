# https://github.com/flant/loghouse



---
kind: ConfigMap
apiVersion: v1
data:
  containers.input.conf: |-
    # Example:
    # {"log":"[info:2016-02-16T16:04:05.930-08:00] Some log text here\n","stream":"stdout","time":"2016-02-17T00:04:05.931087621Z"}
    <source>
      type tail
      path /var/log/containers/*.log
      pos_file /var/log/containers.log.pos
      time_format %Y-%m-%dT%H:%M:%S.%NZ
      tag kubernetes.*
      format json
      keep_time_key true
      read_from_head true
    </source>
  system.input.conf: |-
    # Logs from systemd-journal for interesting services.
    <source>
      type systemd
      filters [{ "_SYSTEMD_UNIT": "docker.service" }]
      pos_file /var/log/gcp-journald-docker.pos
      read_from_head true
      tag docker
    </source>
    <source>
      type systemd
      filters [{ "_SYSTEMD_UNIT": "kubelet.service" }]
      pos_file /var/log/gcp-journald-kubelet.pos
      read_from_head true
      tag kubelet
    </source>
  forward.input.conf: |-
    # Takes the messages sent over TCP
    <source>
      type forward
    </source>
  monitoring.conf: |-
    # Prometheus Exporter Plugin
    # input plugin that exports metrics
    <source>
      @type prometheus
    </source>
    <source>
      @type monitor_agent
    </source>
    # input plugin that collects metrics from MonitorAgent
    <source>
      @type prometheus_monitor
      <labels>
        host ${hostname}
      </labels>
    </source>
    # input plugin that collects metrics for output plugin
    <source>
      @type prometheus_output_monitor
      <labels>
        host ${hostname}
      </labels>
    </source>
    # input plugin that collects metrics for in_tail plugin
    <source>
      @type prometheus_tail_monitor
      <labels>
        host ${hostname}
      </labels>
    </source>
  output.conf: |-
    # Enriches records with Kubernetes metadata
    <filter kubernetes.**>
      type kubernetes_metadata
      merge_json_log false
    </filter>
    <filter kubernetes.**>
      @type record_modifier
      <record>
        _json_log_             ${ log = record["log"].strip; if log[0].eql?('{') && log[-1].eql?('}'); begin; JSON.parse(log); rescue JSON::ParserError; end; end }
        timestamp              ${time}
        nsec                   ${record["time"].split('.').last.to_i}
        # static fields
        source                 "kubernetes"
        namespace              ${record["kubernetes"]["namespace_name"]}
        host                   ${record["kubernetes"]["host"]}
        pod_name               ${record["kubernetes"]["pod_name"]}
        container_name         ${record["kubernetes"]["container_name"]}
        stream                 ${record["stream"]}
        # dynamic fields
        labels.names           ${record["kubernetes"]["labels"].keys}
        labels.values          ${record["kubernetes"]["labels"].values}
        string_fields.names    ${record["_json_log_"] ? record["_json_log_"].select{|_, v| !v.nil? && !v.is_a?(Numeric) && !v.is_a?(TrueClass) && !v.is_a?(FalseClass)}.keys : ["log"]}
        string_fields.values   ${record["_json_log_"] ? record["_json_log_"].select{|_, v| !v.nil? && !v.is_a?(Numeric) && !v.is_a?(TrueClass) && !v.is_a?(FalseClass)}.values.map(&:to_s) : [record["log"]]}
        number_fields.names    ${record["_json_log_"] ? record["_json_log_"].select{|_, v| v.is_a?(Numeric)}.keys : []}
        number_fields.values   ${record["_json_log_"] ? record["_json_log_"].select{|_, v| v.is_a?(Numeric)}.values : []}
        boolean_fields.names   ${record["_json_log_"] ? record["_json_log_"].select{|_, v| v.is_a?(TrueClass) || v.is_a?(FalseClass)}.keys : []}
        boolean_fields.values  ${record["_json_log_"] ? record["_json_log_"].select{|_, v| v.is_a?(TrueClass) || v.is_a?(FalseClass)}.values.map{|v| v ? 1 : 0} : []}
        null_fields.names      ${record["_json_log_"] ? record["_json_log_"].select{|_, v| v.nil?}.keys : []}
      </record>
      remove_keys kubernetes, docker, master_url, time, log, _json_log_
     </filter>
    <filter docker.**>
      @type record_modifier
      <record>
        timestamp              ${time}
        source                 "docker"
        host                   ${record["_HOSTNAME"]}
        stream                 ${record["_TRANSPORT"]}
        string_fields.names    ${["log"]}
        string_fields.values   ${[record["MESSAGE"]]}
      </record>
      remove_keys _TRANSPORT, PRIORITY, SYSLOG_FACILITY, _UID, _GID, _CAP_EFFECTIVE, _SYSTEMD_SLICE, _BOOT_ID, _MACHINE_ID, _HOSTNAME, SYSLOG_IDENTIFIER, _PID, _COMM, _EXE, _CMDLINE, _SYSTEMD_CGROUP, _SYSTEMD_UNIT, MESSAGE
    </filter>
    <filter kubelet.**>
      @type record_modifier
      <record>
        timestamp              ${time}
        source                 "kubelet"
        host                   ${record["_HOSTNAME"]}
        stream                 ${record["_TRANSPORT"]}
        string_fields.names    ${["log"]}
        string_fields.values   ${[record["MESSAGE"]]}
      </record>
      remove_keys _TRANSPORT, PRIORITY, SYSLOG_FACILITY, _UID, _GID, _CAP_EFFECTIVE, _SYSTEMD_SLICE, _BOOT_ID, _MACHINE_ID, _HOSTNAME, SYSLOG_IDENTIFIER, _PID, _COMM, _EXE, _CMDLINE, _SYSTEMD_CGROUP, _SYSTEMD_UNIT, MESSAGE
    </filter> 
    <match **>
      @type exec
      command bash /usr/local/bin/insert_ch.sh
      format json
      buffer_type memory
      buffer_chunk_limit 64m
      buffer_queue_limit 32
      flush_at_shutdown true
      flush_interval 1s
      num_threads 4
    </match>

metadata:
  name: fluentd-config
  namespace: kube-system
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
    
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fluentd
  namespace: kube-system
  labels:
    k8s-app: fluentd
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: fluentd
  labels:
    k8s-app: fluentd
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
rules:
- apiGroups:
  - ""
  resources:
  - "namespaces"
  - "pods"
  verbs:
  - "get"
  - "watch"
  - "list"
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1beta1
metadata:
  name: fluentd
  labels:
    k8s-app: fluentd
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile 
subjects:
- kind: ServiceAccount
  name: fluentd
  namespace: kube-system
  apiGroup: ""
roleRef:
  kind: ClusterRole
  name: fluentd
  apiGroup: ""    
  
---
apiVersion: extensions/v1beta1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
  labels:
    k8s-app: fluentd
    kubernetes.io/cluster-service: "true"
    addonmanager.kubernetes.io/mode: Reconcile
spec:
  template:
    metadata:
      labels:
        k8s-app: fluentd
        kubernetes.io/cluster-service: "true"
      annotations:
        scheduler.alpha.kubernetes.io/critical-pod: ''
    spec:
      serviceAccountName: fluentd
      containers:
      - name: fluentd
        image: flant/loghouse-fluentd:0.0.2
        imagePullPolicy: IfNotPresent
        env:
        - name: FLUENTD_ARGS
          value: --no-supervisor -q
        - name: CLICKHOUSE_SERVER
          value: "clickhouse"
        - name: CLICKHOUSE_PORT
          value: "9000"
        - name: CLICKHOUSE_USER
          value: "default"
        - name: CLICKHOUSE_PASS
          value: "password"
        - name: CLICKHOUSE_DB
          value: "logs"
        - name: K8S_LOGS_TABLE
          value: "logs"
#        resources:
#          limits:
#            memory: 100m
#            cpu: 512Mi
#          requests:
#            memory: 50m
#            cpu: 256Mi
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: libsystemddir
          mountPath: /host/lib
          readOnly: true
        - name: config-volume
          mountPath: /etc/fluent/config.d
      terminationGracePeriodSeconds: 30    
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: libsystemddir
        hostPath:
          path: /usr/lib64
      - name: config-volume
        configMap:
          name: fluentd-config
          
          
---







kind: ConfigMap
apiVersion: v1
data:
  config.xml: |-
    <?xml version="1.0"?>
    <yandex>
        <logger>
            <level>warning</level>
            <log>/var/log/clickhouse-server/clickhouse-server.log</log>
            <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
            <size>100M</size>
            <count>7</count>
        </logger>
        <http_port>8123</http_port>
        <tcp_port>9000</tcp_port>
        <listen_host>0.0.0.0</listen_host>
        <max_connections>4096</max_connections>
        <keep_alive_timeout>3</keep_alive_timeout>
        <max_concurrent_queries>100</max_concurrent_queries>
        <uncompressed_cache_size>8589934592</uncompressed_cache_size>
        <mark_cache_size>5368709120</mark_cache_size>
        <path>/var/lib/clickhouse/</path>
        <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>
        <users_config>users.xml</users_config>
        <default_profile>default</default_profile>
        <default_database>default</default_database>
        <remote_servers incl="clickhouse_remote_servers" />
        <zookeeper incl="zookeeper-servers" optional="true" />
        <macros incl="macros" optional="true" />
        <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>
        <max_session_timeout>3600</max_session_timeout>
        <default_session_timeout>60</default_session_timeout>
        <query_log>
            <database>system</database>
            <table>query_log</table>
            <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        </query_log>
        <dictionaries_config>*_dictionary.xml</dictionaries_config>
        <compression incl="clickhouse_compression">
        </compression>
        <resharding>
            <task_queue_path>/clickhouse/task_queue</task_queue_path>
        </resharding>
        <distributed_ddl>
            <path>/clickhouse/task_queue/ddl</path>
        </distributed_ddl>
    </yandex>
  users.xml: |-
    <?xml version="1.0"?>
    <yandex>
        <profiles>
            <default>
                <max_memory_usage>10000000000</max_memory_usage>
                <use_uncompressed_cache>0</use_uncompressed_cache>
                <load_balancing>random</load_balancing>
            </default>
            <readonly>
                <readonly>1</readonly>
            </readonly>
        </profiles>
        <users>
            <default>
                <password_sha256_hex>5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8</password_sha256_hex>
                <networks incl="networks" replace="replace">
                    <ip>::/0</ip>
                </networks>
                <profile>default</profile>
                <quota>default</quota>
            </default>
        </users>
        <quotas>
            <default>
                <interval>
                    <duration>3600</duration>
                    <queries>0</queries>
                    <errors>0</errors>
                    <result_rows>0</result_rows>
                    <read_rows>0</read_rows>
                    <execution_time>0</execution_time>
                </interval>
            </default>
        </quotas>
    </yandex>
metadata:
  name: clickhouse-config
  namespace: kube-system
  labels:
    addonmanager.kubernetes.io/mode: Reconcile      
---


---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-clickhouse
  namespace: kube-system
  annotations:
    volume.beta.kubernetes.io/mount-options: "discard"
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
#      storage: 20Gi
      storage: 1Gi
#  storageClassName: slow


---
apiVersion: v1
kind: Service
metadata:
  name: clickhouse
  namespace: kube-system
spec:
  selector:
    component: clickhouse
  ports:
  - name: http
    port: 8123
    targetPort: 8123
    protocol: TCP
  - name: native
    port: 9000
    targetPort: 9000
    protocol: TCP  
    
---
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: clickhouse-server
  namespace: kube-system
spec:
  revisionHistoryLimit: 1
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        component: clickhouse
    spec:
      initContainers:
      - name: chown
        image: alpine:3.6
        command: ['/bin/sh', '-c', 'chown 105:106 -R /var/lib/clickhouse']
        volumeMounts:
        - name: pvc-clickhouse
          mountPath: /var/lib/clickhouse
      containers:
      - name: clickhouse
        image: flant/loghouse-clickhouse:0.0.2
        imagePullPolicy: IfNotPresent
        ports:
        - name: http
          containerPort: 8123
        - name: native
          containerPort: 9000
        env:
        - name: CLICKHOUSE_SERVER
          value: "clickhouse"
        - name: CLICKHOUSE_PORT
          value: "9000"
        - name: CLICKHOUSE_USER
          value: "default"
        - name: CLICKHOUSE_PASS
          value: "password"
        - name: CLICKHOUSE_DB
          value: "logs"
        - name: K8S_LOGS_TABLE
          value: "logs"
        livenessProbe:
          timeoutSeconds: 1
          initialDelaySeconds: 30
          tcpSocket:
            port: 9000
        readinessProbe:
          timeoutSeconds: 1
          initialDelaySeconds: 5
          tcpSocket:
            port: 9000
        resources:
          limits:
            cpu: 4
            memory: 8Gi
          requests:
            cpu: 1
            memory: 4Gi
        volumeMounts:
          - name: pvc-clickhouse
            mountPath: /var/lib/clickhouse/
          - name: config-volume
            mountPath: /etc/clickhouse-server/
      volumes:
        - name: pvc-clickhouse
          persistentVolumeClaim:
            claimName: pvc-clickhouse
        - name: config-volume
          configMap:
            name: clickhouse-config
#      nodeSelector:
#        'node-role/logging': ''
        




---
kind: ConfigMap
apiVersion: v1
metadata:
  name: loghouse-user-config
  namespace: kube-system
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
data:
  user.conf: |-
    admin:
      - ".*"        

      
      
---
apiVersion: batch/v2alpha1
kind: CronJob
metadata:
  name: logs-tables
  namespace: kube-system
spec:
  schedule: "59 23 * * *"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          restartPolicy: OnFailure
          initContainers:
          - name: wait-clickhouse
            image: alpine:3.6
            command: ['/bin/sh', '-c', 'while ! getent ahostsv4 clickhouse; do sleep 1; done']
          containers:
            - name: cron
              image: flant/loghouse-dashboard:0.0.2
              imagePullPolicy: IfNotPresent
              command: ['/bin/bash', '-l', '-c', 'rake create_logs_tables']
              env:
              - name: KUBERNETES_DEPLOYED
                value: "now"
              - name: CLICKHOUSE_URL
                value: "clickhouse:8123"
              - name: CLICKHOUSE_USERNAME
                value: "default"
              - name: CLICKHOUSE_PASSWORD
                value: "password"
              - name: CLICKHOUSE_DATABASE
                value: "logs"
# Custom partitioning, using LOGS_TABLES_PARTITION_PERIOD variable, in hours.
# 24 must be divisible by this value for now, so tables always can start with 00 hours (it's skipped for 24). Default is 24, as it was.                
              - name: LOGS_TABLES_PARTITION_PERIOD
                value: "1"
              - name: CLICKHOUSE_LOGS_TABLE
                value: "logs"


---
apiVersion: batch/v1
kind: Job
metadata:
  name: logs-init-db
  namespace: kube-system
spec:
  activeDeadlineSeconds: 300
  template:
    metadata:
      name: logs-init-db
    spec:
      restartPolicy: OnFailure
      initContainers:
      - name: wait-clickhouse
        image: alpine:3.6
        command: [ '/bin/sh', '-c', 'while ! getent ahostsv4 clickhouse; do sleep 1; done' ]
      containers:
      - name: init
        image: flant/loghouse-fluentd:0.0.2
        imagePullPolicy: IfNotPresent
        command: ['/bin/bash', '-l', '-c', 'clickhouse-client --host=${CLICKHOUSE_URL} --port=9000 --user=${CLICKHOUSE_USERNAME} --password=${CLICKHOUSE_PASSWORD} --query="CREATE DATABASE ${CLICKHOUSE_DATABASE};"']
        env:
        - name: KUBERNETES_DEPLOYED
          value: "now"
        - name: CLICKHOUSE_URL
          value: "clickhouse"
        - name: CLICKHOUSE_USERNAME
          value: "default"
        - name: CLICKHOUSE_PASSWORD
          value: "password"
        - name: CLICKHOUSE_DATABASE
          value: "logs"
        - name: CLICKHOUSE_LOGS_TABLE
          value: "logs"
        - name: LOGS_TABLES_PARTITION_PERIOD
          value: "1"
        - name: RACK_ENV
          value: "production"     

---
apiVersion: batch/v1
kind: Job
metadata:
  name: logs-init-tables
  namespace: kube-system
spec:
  activeDeadlineSeconds: 160
  template:
    metadata:
      name: logs-init-tables
    spec:
      restartPolicy: OnFailure
      initContainers:
      - name: wait-clickhouse
        image: alpine:3.6
        command: [ '/bin/sh', '-c', 'while ! getent ahostsv4 clickhouse; do sleep 1; done' ]
      containers:
      - name: init-tables
        image: flant/loghouse-dashboard:0.0.2
        imagePullPolicy: IfNotPresent
        command: ['/bin/bash', '-l', '-c', 'rake create_logs_tables']
        env:
        - name: KUBERNETES_DEPLOYED
          value: "now"
        - name: CLICKHOUSE_URL
          value: "clickhouse:8123"
        - name: CLICKHOUSE_USERNAME
          value: "default"
        - name: CLICKHOUSE_PASSWORD
          value: "password"
        - name: CLICKHOUSE_DATABASE
          value: "logs"
        - name: CLICKHOUSE_LOGS_TABLE
          value: "logs"
        - name: LOGS_TABLES_PARTITION_PERIOD
          value: "1"
        - name: RACK_ENV
          value: "production" 
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: loghouse
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRole
metadata:
  name: loghouse
rules:
- apiGroups:
  - ""
  resources:
  - namespaces
  verbs:
  - get
  - list
---
apiVersion: rbac.authorization.k8s.io/v1beta1
kind: ClusterRoleBinding
metadata:
  name: loghouse
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: loghouse
subjects:
- kind: ServiceAccount
  name: loghouse
  namespace: kube-system
  
  
  
---  

---
kind: ConfigMap
apiVersion: v1
metadata:
  name: loghouse-nginx-conf
  namespace: kube-system
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
data:
  nginx.conf: |-
    worker_processes auto;
    daemon off;
    error_log /dev/stderr info;
    events {
      worker_connections 1024;
    }
    http {
      access_log /dev/stdout;
      include /etc/nginx/mime.types;
      gzip on;
      gzip_disable "msie6";
      gzip_types text/plain text/css text/xml text/javascript application/javascript application/x-javascript application/xml image/jpeg image/png;
      set_real_ip_from 192.168.0.0/16;
      set_real_ip_from 10.0.0.0/8;
      set_real_ip_from 172.16.0.0/12;
      server {
        server_name _;
        listen 80;
        location / {
          auth_basic "Authrentication Required";
          auth_basic_user_file /nginx/passwd/auth;
          proxy_redirect      off;
          proxy_set_header    Host          $http_host;
          proxy_set_header    X-Real-Ip     $remote_addr;
          proxy_set_header    X-Forwarded-For   $proxy_add_x_forwarded_for;
          proxy_pass http://127.0.0.1:9292;
        }
      }
    } 
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: loghouse-user-config
  namespace: kube-system
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
data:
  user.conf: |-
    admin:
      - ".*"
---

apiVersion: v1
data:
# command: echo "PASSWORD" | htpasswd -ni admin | base64 -w0
# result: YWRtaW46JGFwcjEkMzdxSEwvTVIkcEFvdzEzZDUwMkd5VFc2VDNlQmJiMAoK
  auth: "YWRtaW46JGFwcjEkelhESkU5YTkkRkU0OFdnZlBMZlJJQjk0bVhXZVprMAoK"
kind: Secret
metadata:
  name: basic-auth
  namespace: kube-system
type: Opaque

---

apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: loghouse
  namespace: kube-system
spec:
  revisionHistoryLimit: 1
  replicas: 1
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        component: loghouse
    spec:
      serviceAccountName: loghouse
      containers:
      - name: frontend
        image: nginx:alpine
        command: ["/usr/sbin/nginx"]
        ports:
        - name: http
          containerPort: 80
        env:
        - name: KUBERNETES_DEPLOYED
          value: "now"
        volumeMounts:
        - name: basic-auth
          mountPath: "/nginx/passwd"
          readOnly: true
        - name: nginx-conf
          mountPath: /etc/nginx/nginx.conf
          subPath: nginx.conf
      - name: backend
        image: flant/loghouse-dashboard:0.0.2
        imagePullPolicy: IfNotPresent
        command: ["bundle", "exec", "puma"]
        ports:
        - name: http2
          containerPort: 9292
        env:
        - name: KUBERNETES_DEPLOYED
          value: "now"
        - name: CLICKHOUSE_URL
          value: "clickhouse:8123"
        - name: CLICKHOUSE_USERNAME
          value: "default"
        - name: CLICKHOUSE_PASSWORD
          value: "password"
        - name: CLICKHOUSE_DATABASE
          value: "logs"
        - name: CLICKHOUSE_LOGS_TABLE
          value: "logs"
        - name: LOGS_TABLES_PARTITION_PERIOD
          value: "1"
        - name: PERMISSONS_FILE_PATH
          value: "/config/user.conf"
        - name: RACK_ENV
          value: "production"
        volumeMounts:
        - name: user-config
          mountPath: /config
        livenessProbe:
          tcpSocket:
            port: 9292
        readinessProbe:
          tcpSocket:
            port: 9292
        resources:
          requests:
            memory: 256Mi
            cpu: 0.5
          limits:
            memory: 1Gi
            cpu: 1
      volumes:
      - name: user-config
        configMap:
          name: loghouse-user-config
      - name: basic-auth
        secret:
          secretName: basic-auth
      - name: nginx-conf
        configMap:
          name: loghouse-nginx-conf









---
# apiVersion: apps/v1beta1
# kind: Deployment
# metadata:
  # name: tabix
  # namespace: kube-system
# spec:
  # revisionHistoryLimit: 1
  # replicas: 1
  # strategy:
    # type: Recreate
  # template:
    # metadata:
      # labels:
        # component: tabix
    # spec:
      # containers:
      # - name: tabix
        # image: flant/loghouse-tabix:0.0.2
        # imagePullPolicy: IfNotPresent
        # ports:
        # - name: http
          # containerPort: 80
        # livenessProbe:
          # timeoutSeconds: 1
          # initialDelaySeconds: 60
          # tcpSocket:
            # port: 80
        # readinessProbe:
          # timeoutSeconds: 1
          # initialDelaySeconds: 5
          # tcpSocket:
            # port: 80
        # resources:
          # requests:
            # cpu: 0.2
            # memory: 256Mi
          # limits:
            # cpu: 0.5
            # memory: 512Mi
---
# apiVersion: v1
# kind: Service
# metadata:
  # name: tabix
  # namespace: kube-system
# spec:
  # selector:
    # component: tabix
  # ports:
  # - name: http
    # port: 80
    # targetPort: 80
    # protocol: TCP       
    
---
# apiVersion: v1
# kind: Service
# metadata:
  # name: loghouse
  # namespace: kube-system
# spec:
  # selector:
    # component: loghouse
  # ports:
  # - name: http
    # port: 80
    # targetPort: 80
    # protocol: TCP    